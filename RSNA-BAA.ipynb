{"cells":[{"cell_type":"markdown","metadata":{"id":"EcDuecd5TLKq"},"source":["# Generate *.npy Data with data_utils.py\n","\n","Generate data.pkl, data_age.pkl, and data_gender.pkl. （see pickle python obj serialization)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOGOPuLlrTx3"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import os\n","import pandas as pd\n","from six.moves import cPickle\n","#file op\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHmMs4d5YJbz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646766069423,"user_tz":480,"elapsed":1020,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"aeda0c36-8b51-44ae-af43-d358048664dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path += '/content/drive/MyDrive/csb185_boneAge'\n"]},{"cell_type":"code","source":["#Check GPU, RAM condition\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-WHucnedw-Q","executionInfo":{"status":"ok","timestamp":1646918416563,"user_tz":480,"elapsed":319,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"aa1c1452-3bf8-42d2-8e0c-f7d7991d2df8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Mar 10 13:20:16 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["!pwd\n","root_dir = '/content/drive/MyDrive/csb185_boneAge/data_rsna_kaggle/'\n","train_dir = os.path.join(root_dir,'boneage-training-dataset/boneage-training-dataset/')\n","checkpointt_dir = os.path.join(mydrive,'weights2/')"],"metadata":{"id":"6f7oAYwKb5ya","executionInfo":{"status":"ok","timestamp":1646766106205,"user_tz":480,"elapsed":327,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd7415ab-cc0e-4d93-96eb-b2d1df09c780"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","metadata":{"id":"rGzoVY1-NOYh"},"source":["# generate initial data files\n"]},{"cell_type":"markdown","source":["Skip this part by loading the generated files "],"metadata":{"id":"b7UIzqap6PMX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cgwh7t-skVB"},"outputs":[],"source":["#For this problem the validation and test data provided by the concerned authority did not have labels\n","#so the training data was split into train, test and validation sets data directory\n","# Original RSNA-Kaggle dataset contains = 12611 images\n","\n","X_train = []\n","y_age = []\n","y_gender = []\n","\n","df = pd.read_csv(os.path.join(root_dir,'boneage-training-dataset.csv')) \n","a = df.to_numpy()\n","m = a.shape[0]\n"]},{"cell_type":"code","source":["path = train_dir  #split from above read.csv() for better running\n","print ('Loading data set...')\n","\n","##= with a smaller sample, with random 50% of 15GB data (below 3 lines)\n","files = [f for f in os.listdir(path)]\n","random_files = np.random.choice(files, int(len(files)/12611*1390))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXLCaakUJrOT","executionInfo":{"status":"ok","timestamp":1646616812481,"user_tz":480,"elapsed":294,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"3d10d2be-27cf-415c-a125-dd5bebbe7f2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data set...\n"]}]},{"cell_type":"code","source":["file_pkl = open(os.path.join(root_dir,'file.pkl'),'wb')\n","cPickle.dump(random_files, file_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","file_pkl.close()"],"metadata":{"id":"2oPZgKAxopcW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(random_files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjHVLqUGB1N5","executionInfo":{"status":"ok","timestamp":1646617195333,"user_tz":480,"elapsed":146,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"fc6f6f17-152d-409c-ae7d-ac98404e689e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1390"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["for i in random_files:\n","#for i in os.listdir(path): \n","    y_age.append(df.boneage[df.id == int(i[:-4])].tolist()[0])\n","    a = df.male[df.id == int(i[:-4])].tolist()[0]\n","    if a:\n","        y_gender.append(1)\n","    else:\n","        y_gender.append(0)\n","    img_path = path + i\n","    shutil.copy(img_path, root_dir+'temp_train/')   #save to local path\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img,(300,300))\n","    x = np.asarray(img, dtype=np.uint8)\n","    X_train.append(x)\n","    \n","print ('100% completed loading data')"],"metadata":{"id":"SxGyN5u-omzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646617310449,"user_tz":480,"elapsed":67397,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"93c7054f-6b0f-40ee-8c5c-3db7eb3c88a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100% completed loading data\n"]}]},{"cell_type":"code","source":["len(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xuFLFw2dCAAB","executionInfo":{"status":"ok","timestamp":1646617679257,"user_tz":480,"elapsed":173,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"22a69fe0-d5da-431a-ef9b-d757dfada8f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1390"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpLSMtu1GAf6"},"outputs":[],"source":["# Save data to .pkl files\n","train_pkl = open(os.path.join(root_dir,'data.pkl'),'wb')\n","cPickle.dump(X_train, train_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","train_pkl.close()\n","\n","train_age_pkl = open(os.path.join(root_dir,'data_age.pkl'),'wb')\n","cPickle.dump(y_age, train_age_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","train_age_pkl.close()\n","\n","train_gender_pkl = open(os.path.join(root_dir,'data_gender.pkl'),'wb')\n","cPickle.dump(y_gender, train_gender_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","train_gender_pkl.close()\n"]},{"cell_type":"code","source":["len(list(os.listdir(os.path.join(root_dir,'temp_train'))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAw_Kva3BmOU","executionInfo":{"status":"ok","timestamp":1646617440486,"user_tz":480,"elapsed":194,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"ab8fa70d-99cf-4cb3-db67-fa86a0fef47a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1321"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"EqLZSkGPeL7C"},"source":["#Run main_classification.py to train classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DS8zEo56DNsL"},"outputs":[],"source":["!pip install visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qquZvDOYYZZ6"},"outputs":[],"source":["%cd /content/drive/MyDrive/csb185_boneAge\n","from func_utils import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJ1T5TQmedYL"},"outputs":[],"source":["import pickle\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import keras\n","import tensorflow\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.xception import Xception\n","from keras.preprocessing import image\n","from keras.models import Model, load_model\n","from keras.layers import Flatten, Dense, Input, Reshape, Lambda\n","from keras import backend as K\n","from keras import optimizers\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n","os.environ['OMP_NUM_THREADS']='6'\n","batch_size = 32\n","epochs = 30\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4306,"status":"ok","timestamp":1646617619405,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"},"user_tz":480},"id":"Odybxtmf0ZKo","outputId":"5272cd8f-1c29-4e8d-f041-718dc204f0e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["...loading training data\n"]}],"source":["# Load data\n","f = open(root_dir+'data_age.pkl', 'rb')\n","y = pickle.load(f)\n","f.close()\n","\n","f = open(root_dir+'data_gender.pkl','rb')\n","gender = pickle.load(f)\n","f.close()\n","\n","print('...loading training data')\n","f = open(root_dir+'data.pkl', 'rb')\n","x = pickle.load(f)\n","f.close()\n","\n","x = np.asarray(x, dtype=np.float32) #takes 18GB of RAM\n","y = np.asarray(y)\n","gender = np.asarray(gender)\n","\n","x /= 255.\n","gender =2*( gender-0.5) #1, 0 -> 1, -1 M, F\n","x_final = []\n","y_final = []\n","gender_final = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9Eda9S84bwC"},"outputs":[],"source":["print('sample size: ', x.shape, ' age size: ', y.shape, ' gender size: ', gender.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_343YPieejyp"},"outputs":[],"source":["# Shuffle images and split into train, validation and test sets\n","#random_no = np.random.choice(x.shape[0], size=x.shape[0], replace=False)\n","random_no = np.arange(x.shape[0])\n","np.random.seed(0)\n","np.random.shuffle(random_no)\n","for i in random_no:\n","    x_final.append(x[i,:,:,:])\n","    y_final.append(y[i])\n","    gender_final.append(gender[i])\n","\n","x_final = np.asarray(x_final)\n","y_final = np.asarray(y_final)\n","gender_final = np.asarray(gender_final)\n","\n","k = 55 # Decides split count \n","x_test = x_final[:k,:,:,:]\n","y_test = y_final[:k]\n","gender_test = gender_final[:k]\n","\n","x_valid = x_final[k:2*k,:,:,:]\n","y_valid = y_final[k:2*k]\n","gender_valid = gender_final[k:2*k]\n","\n","x_train = x_final[2*k:,:,:,:]\n","y_train = y_final[2*k:]\n","gender_train = gender_final[2*k:]\n","\n","#y_test = keras.utils.to_categorical(y_test,240)\n","#y_train = keras.utils.to_categorical(y_train,240)\n","#y_valid = keras.utils.to_categorical(y_valid,240)\n","y_train = softlabel(y_train,240) #see func utils\n","y_valid = softlabel(y_valid,240)\n","y_test = softlabel(y_test,240)\n","print (y_train[0,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"El7JoH8R6Ro1"},"outputs":[],"source":["print ('x_train shape:'+ str(x_train.shape))\n","print ('y_train shape:'+ str(y_train.shape))\n","print ('gender_train shape:'+ str(gender_train.shape))\n","print ('x_valid shape:'+ str(x_valid.shape))\n","print ('y_valid shape:'+ str(y_valid.shape))\n","print ('gender_valid shape:' + str(gender_valid.shape))\n","print ('x_test shape:'+ str(x_test.shape))\n","print ('y_test shape:'+ str(y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"jQybLYk67swD"},"source":["Concatenate gender\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Imv4cy3t0g4P"},"outputs":[],"source":["# Using VGG19 with pretrained weights from Imagenet but stil gender is embedded and concact'd\n","base_model = InceptionV3(weights='imagenet', include_top=False)\n","for i,layer in enumerate(base_model.layers):\n","    print (i,layer.name)\n","input = Input(shape=(300,300,3),name='input1')\n","input_gender = Input(shape=(1,),dtype='float32',name='input2')\n","output = base_model(input)\n","gender_embedding=Dense(16)(input_gender)\n","#gender_embedding=Dense(12)(gender_embedding)\n","#x = keras.layers.MaxPooling2D(pool_size=(3,3))(output)\n","#x = keras.layers.Conv2D(512,kernel_size=(3,3))(x)\n","#x = keras.layers.Conv2D(256,kernel_size=(1,1))(x)\n","print (K.int_shape(output))\n","x = keras.layers.MaxPooling2D(pool_size=(8,8))(output)\n","print (K.int_shape(x))\n","x = Flatten()(x)\n","f = keras.layers.Concatenate(axis=1)([x,gender_embedding])\n","print (K.int_shape(f)) \n","#x = Dense(256, activation='relu')(x)\n","predictions = Dense(240)(x)\n"]},{"cell_type":"markdown","source":["compile model"],"metadata":{"id":"ADMMOvan6sJu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQ2fq8ob0osu"},"outputs":[],"source":["model = Model(inputs=[input,input_gender], outputs=predictions)\n","for i,layer in enumerate(model.layers):\n","    print(i,layer.name)\n","\n","Adam = tensorflow.keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.9,beta_2=0.999)\n","model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n","\n"]},{"cell_type":"code","source":["\n","# Save weights after every epoch\n","checkpoint = keras.callbacks.ModelCheckpoint(filepath=root_dir+'weights/weights.{epoch:02d}-{val_loss:.2f}.hdf5',save_weights_only=True)\n","history=model.fit([x_train,gender_train],y_train,batch_size=batch_size,epochs=60,verbose=1,validation_data=([x_valid,gender_valid],y_valid), callbacks = [checkpoint])\n","score = model.evaluate([x_test,gender_test], y_test, batch_size=batch_size)\n","print('Test loss:', score[0])\n","print('Test MAE:', score[1])\n","\n","#TestMAE = TestMAE(model,x_test,y_test,gender_test)\n","#print ('TestMAE:',TestMAE)\n","##Visulization\n","weights = model.layers[-1].get_weights()[0]\n","print(weights.shape)"],"metadata":{"id":"BvqTIq8LJCYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#for layer in base_model.layers[:16]:\n","#    layer.trainable=False\n","#for layer in base_model.layers:\n","#    print (layer.name,layer.trainable)\n","Adam = tensorflow.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9, beta_2=0.999)\n","model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n","history = model.fit([x_train,gender_train],y_train,batch_size=batch_size,epochs=30,verbose=1,validation_data=([x_valid,gender_valid],y_valid), callbacks = [checkpoint])\n","score = model.evaluate([x_test,gender_test], y_test, batch_size=batch_size)\n","print('Test loss:', score[0])\n","print('Test MAE:', score[1])\n","\n","#TestMAE = TestMAE(model,x_test,y_test,gender_test)\n","#print ('TestMAE:',TestMAE)\n","\n","weights = model.layers[-1].get_weights()[0]\n","print (weights.shape)\n"],"metadata":{"id":"Zle77FZa4Br2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_weights(os.path.join(root_dir,\"model.h5\"))\n","with open(os.path.join(root_dir,'history.pkl'), 'wb') as f:\n","\tpickle.dump(history.history, f)\n","f.close()\n","\n"],"metadata":{"id":"ABymo0Ic4MuC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VcgZsCaQMN0u"},"source":["# Generate Heatmaps for hand region, Region-1"]},{"cell_type":"markdown","metadata":{"id":"qE93XhdyJc2z"},"source":["**GAPAttention(model,weights,image_path)**  \n","heatmap saved in image_path  \n","attentionimg = 0.5 x heatmap + img  \n","**Region 1**  \n","Train the classification model with the original images resized to 560 × 560. The activation outputs (18×18×2048) are then fed into a GMP layer followed by the last FC layer. Derived by applying a binary mask of threshold = 50 (empiracally determined.  \n","**Region 2:**  \n","Trained with original images - Region 1. \n","\n","\n","\n"]},{"cell_type":"code","source":["t_dir = os.path.join(root_dir,'temp_train/')"],"metadata":{"id":"6ARx_Flxd4E8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(list(os.listdir(t_dir)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tijyxIrcEPY4","executionInfo":{"status":"ok","timestamp":1646766299575,"user_tz":480,"elapsed":12889,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"45503f50-79e6-44dd-fd01-4ea23ab6d014"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1321"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["#weight reload\n","import h5py\n","wf = h5py.File(os.path.join(root_dir,\"model.h5\"), 'r')\n","print(list(wf.keys()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvn3latJLfTZ","executionInfo":{"status":"ok","timestamp":1646766304553,"user_tz":480,"elapsed":413,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"ec46f87b-3919-44fc-85a8-2f8dda98c745"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['dense_1', 'flatten', 'inception_v3', 'input1', 'input2', 'max_pooling2d_4', 'top_level_model_weights']\n"]}]},{"cell_type":"code","source":["# someone overrides the file i think\n","model.load_weights(os.path.join(root_dir,\"modelver.h5\"))\n","weights = model.layers[-1].get_weights()[0]\n","print(weights.shape)#2048240"],"metadata":{"id":"JLc60jTpHc5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#reload history for graph\n","f = open(os.path.join(root_dir,'history.pkl'), 'rb')\n","history = pickle.load(f)\n","f.close()\n"],"metadata":{"id":"qND6dQ7tHc5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layer=K.function(model.layers[0].input, [model.layers[1].get_output_at(-1), model.layers[-1].output])\n","layer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wj96mlQVOY05","executionInfo":{"status":"ok","timestamp":1646602956128,"user_tz":480,"elapsed":122,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"07412851-5c73-444e-ff8f-8504ea532bee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function keras.backend.function.<locals>.func>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["#readd file based on x\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuyPEeG26KmB","executionInfo":{"status":"ok","timestamp":1646615167226,"user_tz":480,"elapsed":137,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"9dd9cbd6-0e64-44a9-e619-973749510929"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1390,)"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pjnXyZ_MSM_"},"outputs":[],"source":["#because GAP is used instead of GMP for hand localization\n","def GAPAttention(model,weights,image_path):\n","    file_list = os.listdir(image_path)\n","    file_list.sort()\n","    for filename in file_list:\n","        filepath=image_path+filename\n","        print(filepath)\n","        image=load_image(filepath)\n","        image = image/255.0\n","        gender=1.0\n","        gender=np.asarray(gender)\n","        gender=np.expand_dims(gender,axis=0)\n","        #backend.function(input, output, update=None): Taking input from the first parameter \n","        #and extracting the number of outputs as per the layers mentioned in the second parameter\n","        layer=K.function([model.layers[0].input, model.layers[4].input], [model.layers[1].get_output_at(-1), model.layers[-1].output])\n","        print(model.layers[0].input.shape)\n","        #Model(inputs=[input,input_gender]) \n","        GAP,prediction=layer([image,gender])\n","        GAP=np.squeeze(GAP,axis=0)\n","        print(GAP.shape)\n","        index = np.argmax(prediction)\n","        print(index)\n","        #weight = weights[:,index]\n","        weight =np.mean(weights[:,index-5:index+5],axis=1)\n","        heatmap = np.zeros((GAP.shape[0],GAP.shape[1]))\n","        for k in range(GAP.shape[2]):\n","            heatmap = heatmap + weight[k]*GAP[:,:,k]\n","        heatmap = heatmap/np.max(heatmap)\n","        heatmap = np.uint8(255*heatmap)\n","        #print(heatmap.shape)\n","        heatmap = cv2.applyColorMap(heatmap,cv2.COLORMAP_JET)\n","        SaveImg(filename,filepath,heatmap)\n","    print ('********** Done ***********')\n","\n","def SaveImg(filename,filepath,heatmap):\n","    img = cv2.imread(filepath)\n","    heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n","    AttentionImg =0.5* heatmap + img\n","    #in case file paths mess up\n","    if not cv2.imwrite(os.path.join('/content/drive/MyDrive/heatmap',filename),heatmap):\n","       raise Exception(\"Could not write heatmap\")\n","    if not cv2.imwrite(os.path.join('/content/drive/MyDrive/AttentionImg',filename),AttentionImg):\n","       raise Exception(\"Could not write AttentionImg\")\n","\n","GAPAttention(model,weights, t_dir)\n","#ShowAttentionV1(base_model, t_dir)"]},{"cell_type":"markdown","metadata":{"id":"hvRCfTdLP6RF"},"source":["# Crop the local patches for hand based on heatmaps\n"]},{"cell_type":"code","source":["#size\n","print(len(os.listdir(t_dir)))\n","print(len(os.listdir('/content/drive/MyDrive/heatmap')))\n","print(len(os.listdir('/content/drive/MyDrive/AttentionImg')))"],"metadata":{"id":"aKyU2_Zq4v4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in os.listdir('/content/drive/MyDrive/Hand/'):\n","    #os.remove('/content/drive/MyDrive/Hand/'+i)"],"metadata":{"id":"CxWlO0ZyOnN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(list(os.listdir('/content/drive/MyDrive/Hand/'))))\n","print(len(list(os.listdir('/content/drive/MyDrive/heatmap/'))))"],"metadata":{"id":"ZzmF2-xyOwZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3qf1aSwQM5a"},"outputs":[],"source":["def crop(img,mask):\n","    index = np.where(mask>0)\n","    top =np.min(index[0])\n","    bottom = np.max(index[0]) \n","    left = np.min(index[1])\n","    right = np.max((index[1]))\n","   # extract hand region\n","   # if top > 200:\n","   #     top =top -200\n","   # elif top > 100:\n","   #     top = top -100\n","\n","   # extract region1\n","   # if left>100:\n","   #     left=left-70\n","\n","    croped_img = img[top:bottom,left:right]\n","    return croped_img\n","\n","\n","\n","def maskout(img,mask):\n","    index = np.where(mask>0)\n","    top =np.min(index[0])\n","    bottom = np.max(index[0]) \n","    left = np.min(index[1])\n","    right = np.max((index[1]))\n","    img[top:bottom,left:right]=np.random.randint(255)\n","    return img\n","\n","\n","def find_max_component(mask):\n","    contours, hierarchy = cv2.findContours(mask,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n","    area = []\n","    for i in range(len(contours)):\n","        area.append(cv2.contourArea(contours[i]))\n","    try:\n","       max_ind = np.argmax(area)\n","    except ValueError: \n","        print(\"Err\")\n","        pass\n","    print (area)\n","    for ind in range(len(contours)):\n","        if ind != max_ind:\n","            cv2.fillConvexPoly(mask,contours[ind],0)\n","    return mask\n","\n","\n","\n","\n","if __name__==\"__main__\":\n","    errimg = []\n","    path_list = os.listdir('/content/drive/MyDrive/heatmap/')\n","    path_list.sort()\n","    kernel = np.ones((5,5),np.uint8)\n","    for path in path_list:\n","      if path.endswith('png'):\n","          img = cv2.imread(os.path.join(t_dir,path),0)\n","      try:\n","          heatmap = cv2.imread(os.path.join('/content/drive/MyDrive/heatmap/',path),0)\n","          #hand thres = 20\n","          ret,mask =  cv2.threshold(heatmap,20,255,cv2.THRESH_BINARY)\n","          mask = find_max_component(mask)\n","                # mask = cv2.dilate(mask,kernel,iterations=1)\n","                # cv2.imwrite('patches/'+path,mask)\n","                # img = img*mask\n","                # cv2.imwrite('patches/'+path,img)\n","          croped_img= crop(img,mask)\n","          if not cv2.imwrite(os.path.join('/content/drive/MyDrive/Hand/',path),croped_img):\n","                print(\"Exception: fail to write img \" + path)\n","      except ValueError: \n","          errimg.append(path)\n","          pass\n","          ##for deriving v2 \n","          #MaskImg = maskout(img,mask)\n","          #cv2.imwrite('Maskout/'+path,MaskImg)"]},{"cell_type":"code","source":["print(len(os.listdir('/content/drive/MyDrive/Hand')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MW9Ep7AMMszN","executionInfo":{"status":"ok","timestamp":1646723293509,"user_tz":480,"elapsed":158,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"5b6bf774-3158-47de-ab4d-35400a136ad3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1319\n"]}]},{"cell_type":"code","source":["#deprecated maybe? not sure\n","print(errimg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsEx0yuRdsWm","executionInfo":{"status":"ok","timestamp":1646723297591,"user_tz":480,"elapsed":215,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"3698bec0-a1df-4a57-e891-3fbc97488888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['3806.png', '6602.png']\n"]}]},{"cell_type":"markdown","metadata":{"id":"hS9jtxf_tD9q"},"source":["# V1"]},{"cell_type":"code","source":["def SaveImg(filename,filepath,heatmap):\n","    img = cv2.imread(filepath)\n","    heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n","    AttentionImg =0.5* heatmap + img\n","    #in case file paths mess up\n","    if not cv2.imwrite(os.path.join('/content/drive/MyDrive/heatmap1',filename),heatmap):\n","       raise Exception(\"Could not write heatmap\")\n","    if not cv2.imwrite(os.path.join('/content/drive/MyDrive/AttentionImg1',filename),AttentionImg):\n","       raise Exception(\"Could not write AttentionImg\")\n"],"metadata":{"id":"N6ifBkL_DiGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model.summary()"],"metadata":{"id":"MTiwtzBaTJn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ShowAttentionV1(model,image_path):\n","    file_list = os.listdir(image_path)\n","    file_list.sort()\n","    for filename in file_list:\n","        print (filename)\n","        filepath=image_path+filename\n","        image=load_image(filepath)\n","        image = image/255.0\n","        gender=1.0\n","        gender=np.asarray(gender)\n","        gender=np.expand_dims(gender,axis=0)\n","        #fed into a GMP layer which follow by the last FC layer.? but of the base model\n","        layer=K.function([model.layers[0].input],[model.layers[196].output])\n","        FeatureMap=layer([image])[0]\n","        print (FeatureMap.shape)\n","        FeatureMap = np.squeeze(FeatureMap, axis=0)\n","        FeatureMap = np.abs(FeatureMap)\n","        heatmap = np.mean(FeatureMap,axis=2)\n","        heatmap = heatmap/np.max(heatmap)\n","        heatmap = np.uint8(255*heatmap)\n","        print (heatmap.shape)\n","        heatmap = cv2.applyColorMap(heatmap,cv2.COLORMAP_JET)\n","        SaveImg(filename,filepath,heatmap)\n","    print ('********** Done ***********')"],"metadata":{"id":"7UFCoCpvE-k2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPd6fWGfGVIb","executionInfo":{"status":"ok","timestamp":1646726724070,"user_tz":480,"elapsed":130,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"e1b09726-20a9-466f-a14c-539441b8db01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method Model.summary of <keras.engine.functional.Functional object at 0x7f8593b552d0>>\n"]}]},{"cell_type":"code","source":["#ShowAttentionV1(base_model, t_dir)\n","\n","if __name__==\"__main__\":\n","    errimg1 = []\n","    path_list = os.listdir(t_dir)\n","    path_list.sort()\n","    print(path_list)\n","    kernel = np.ones((5,5),np.uint8)\n","    for path in path_list:\n","      if path.endswith('png'):\n","          img = cv2.imread(os.path.join(t_dir,path),0)\n","      try:\n","          heatmap = cv2.imread(os.path.join('/content/drive/MyDrive/heatmap/',path),0)\n","          #thres 50\n","          ret,mask =  cv2.threshold(heatmap,50,255,cv2.THRESH_BINARY)\n","          mask = find_max_component(mask)\n","                # mask = cv2.dilate(mask,kernel,iterations=1)\n","                # cv2.imwrite('patches/'+path,mask)\n","                # img = img*mask\n","                # cv2.imwrite('patches/'+path,img)\n","          print(path)\n","          croped_img= crop(img,mask)\n","          if not cv2.imwrite(os.path.join('/content/drive/MyDrive/V1/',path),croped_img):\n","                print(\"Exception: fail to write img\" + path)\n","      except ValueError: \n","          errimg1.append(path)\n","          pass"],"metadata":{"id":"hXDu50Woe34q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(list(os.listdir('/content/drive/MyDrive/AttentionImg1'))))\n","print(len(list(os.listdir('/content/drive/MyDrive/heatmap1'))))\n","print(len(list(os.listdir('/content/drive/MyDrive/V1/'))))"],"metadata":{"id":"bXQVu_EXXPNA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ERASED"],"metadata":{"id":"go0q70p5fUiY"}},{"cell_type":"code","source":["def maskout(img,mask):\n","    index = np.where(mask>0)\n","    top =np.min(index[0])\n","    bottom = np.max(index[0]) \n","    left = np.min(index[1])\n","    right = np.max((index[1]))\n","    img[top:bottom,left:right]=np.random.randint(255)\n","    return img\n"],"metadata":{"id":"rstVhO40mBGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create maskout images \n","if __name__==\"__main__\":\n","    errimg2 = []\n","    path_list = os.listdir(t_dir)\n","    path_list.sort()\n","    #print(path_list)\n","    kernel = np.ones((5,5),np.uint8)\n","    for path in path_list:\n","      if path.endswith('png'):\n","          img = cv2.imread(os.path.join(t_dir,path),0)\n","      try:\n","          heatmap = cv2.imread(os.path.join('/content/drive/MyDrive/heatmap/',path),0)\n","          ret,mask =  cv2.threshold(heatmap,50,255,cv2.THRESH_BINARY)\n","          mask = find_max_component(mask)\n","          MaskImg = maskout(img,mask)\n","          cv2.imwrite(os.path.join('/content/drive/MyDrive/Maskout/',path), MaskImg)\n","\n","                # mask = cv2.dilate(mask,kernel,iterations=1)\n","                # cv2.imwrite('patches/'+path,mask)\n","                # img = img*mask\n","                # cv2.imwrite('patches/'+path,img)\n","          #print(path)\n","          #croped_img= crop(img,mask)\n","          #if not cv2.imwrite(os.path.join('/content/drive/MyDrive/V1/',path),croped_img):\n","                #print(\"Exception: fail to write img\" + path)\n","      except ValueError: \n","          errimg2.append(path)\n","          pass\n","      "],"metadata":{"id":"oGSGGm04e7AP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","print(len(list(os.listdir('/content/drive/MyDrive/Maskout/'))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEp8pK7Nkv5p","executionInfo":{"status":"ok","timestamp":1646728074247,"user_tz":480,"elapsed":153,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"7e4b6b7a-0800-48f8-ca34-2881875d6a2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1319\n"]}]},{"cell_type":"markdown","source":["#aggregate H+R1+E\n"],"metadata":{"id":"KUhcmf9xlZIA"}},{"cell_type":"code","source":["#save r1 e and h regions\n","f = open(root_dir+'data_age.pkl', 'rb')\n","age = pickle.load(f)\n","f.close()\n","\n","f = open(root_dir+'data_gender.pkl','rb')\n","gender = pickle.load(f)\n","f.close()\n","\n","\n"],"metadata":{"id":"11yBq9mhofa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f = open(root_dir+'file.pkl', 'rb')\n","filelist = pickle.load(f)\n","f.close()"],"metadata":{"id":"UpxGwi85ijG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save r1 and e and hby this order\n","print(len(filelist))\n","filelist"],"metadata":{"id":"J_SPbqtZrpEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["handpath = '/content/drive/MyDrive/Hand/'\n","v1path = '/content/drive/MyDrive/V1/'\n","maskout = '/content/drive/MyDrive/Maskout/'\n","mydrive = '/content/drive/MyDrive/'"],"metadata":{"id":"7uzosQ9FsGbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#hand\n","dataHand = []\n","for i in filelist:\n","    imgHand_path = handpath + i\n","    try:\n","      img = cv2.imread(imgHand_path)\n","      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      img = cv2.resize(img,(560,560))\n","    except: \n","        print(\"Err: \"+i)\n","        pass\n","    else:\n","        x = np.asarray(img, dtype=np.uint8)\n","        dataHand.append(x)\n","\n","dataHand_pkl = open(os.path.join(mydrive,'dataHand.pkl'),'wb')\n","cPickle.dump(dataHand, dataHand_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","dataHand_pkl.close()\n","print ('100% completed saving Hand data')"],"metadata":{"id":"Z4z7nrvduY-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#R1\n","dataR1 = []\n","for i in filelist:\n","    try:\n","      imgR1_path = v1path + i\n","      img = cv2.imread(imgR1_path)\n","      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      img = cv2.resize(img,(560,560))\n","    except: \n","        print(\"Err: \"+i)\n","        pass \n","    else:\n","      if (i != '6602.png' and i != '3806.png'):\n","          x = np.asarray(img, dtype=np.uint8)\n","          dataR1.append(x)\n"],"metadata":{"id":"meVM5x01ub9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataR1_pkl = open(os.path.join(mydrive,'dataR1.pkl'),'wb')\n","cPickle.dump(dataR1, dataR1_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","dataR1_pkl.close()\n","print ('100% completed saving R1 data')\n"],"metadata":{"id":"zCD3T2DACJ6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#E\n","dataE = []\n","for i in filelist:\n","    imge_path = maskout + i\n","    try:\n","        img = cv2.imread(imge_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img,(560,560))\n","    except: \n","        print(\"Err: \"+i)\n","        pass \n","    else:\n","      if (i != '6602.png' and i != '3806.png'):\n","          x = np.asarray(img, dtype=np.uint8)\n","          dataE.append(x)\n","\n","dataE_pkl = open(os.path.join(mydrive,'dataE.pkl'),'wb')\n","cPickle.dump(dataE, dataE_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n","dataE_pkl.close()\n","print ('100% completed saving E data')"],"metadata":{"id":"w11V-MO5umv_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","f = open(os.path.join(root_dir,'data_age.pkl'), 'rb')\n","age = pickle.load(f)\n","f.close()\n","\n","f = open(os.path.join(root_dir,'data_gender.pkl'),'rb')\n","gender = pickle.load(f)\n","f.close()"],"metadata":{"id":"k0wLiDJKFrVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#took out the two 6602 3806 update\n","print(list(filelist).index('6602.png'))\n","print(list(filelist).index('3806.png'))"],"metadata":{"id":"OYsT9EIu2ctc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del age[961]\n","del age[892]\n"],"metadata":{"id":"ujXWMRfv5SA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del gender[961]\n","del gender[892]\n"],"metadata":{"id":"9FZbKcEn5den"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#compile regression model"],"metadata":{"id":"BoZAFiGL3xSm"}},{"cell_type":"markdown","source":["120epochs. learningrate set to 0.0003, 0.0001,and 0.00001 first60epochs,next30 epochs, final30epochs,respectively"],"metadata":{"id":"jPiNK0qt35Ov"}},{"cell_type":"code","source":["\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.xception import Xception\n","from keras.preprocessing import image\n","from keras.models import Model, load_model\n","from keras.layers import Flatten, Dense, Input, Reshape, Lambda\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n","os.environ['OMP_NUM_THREADS']='6'\n","batch_size = 16\n","epochs = 30"],"metadata":{"id":"zLuIR7GY9cuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data no need to run\n","mydrive = '/content/drive/MyDrive/'\n","print('...loading training data')\n","f = open(os.path.join(mydrive,'dataE.pkl'), 'rb')\n","dataE = pickle.load(f)\n","f.close()\n","\n","f = open(os.path.join(mydrive,'dataR1.pkl'), 'rb')\n","dataR1 = pickle.load(f)\n","f.close()\n","\n","f = open(os.path.join(mydrive,'dataHand.pkl'), 'rb')\n","dataHand = pickle.load(f)\n","f.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUehzRGQrIuY","executionInfo":{"status":"ok","timestamp":1646735460532,"user_tz":480,"elapsed":26891,"user":{"displayName":"Marlene LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghs6fN3487kaxtRQ8LACqgsYHxpi5bxKEzHwQSGaQ=s64","userId":"04067946524702814420"}},"outputId":"9313449c-bd1c-433a-d1ad-e657a4f36867"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["...loading training data\n"]}]},{"cell_type":"code","source":[" #  Using VGG19 with pretrained weights from Imagenet \n","base_model = Xception(weights='imagenet', include_top=False)\n","for i,layer in enumerate(base_model.layers):\n","    print (i,layer.name)\n","input = Input(shape=(560,560,3),name='input1')\n","input_gender = Input(shape=(1,),dtype='float32',name='input2')\n","output = base_model(input)\n","gender_embedding=Dense(32)(input_gender)\n","#gender_embedding=Dense(12)(gender_embedding)\n","#x = keras.layers.MaxPooling2D(pool_size=(5,5))(output)\n","#x = keras.layers.Conv2D(512,kernel_size=(3,3))(x)\n","x = keras.layers.Conv2D(256,kernel_size=(3,3))(output)\n","print (K.int_shape(output))\n","x = keras.layers.MaxPooling2D(pool_size=(3,3))(x)\n","print (K.int_shape(x))\n","x=Flatten()(x)\n","f = keras.layers.Concatenate(axis=1)([x,gender_embedding])\n","print (K.int_shape(f)) \n","#x = Dense(256, activation='relu')(x)\n","predictions = Dense(1)(f)\n","\n","\n"],"metadata":{"id":"4SnGHYDwkjaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(inputs=[input,input_gender], outputs=predictions)\n","for i,layer in enumerate(model.layers):\n","    print (i,layer.name)\n","\n","Adam=tensorflow.keras.optimizers.Adam(lr=0.0003,beta_1=0.9,beta_2=0.999)\n","model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])"],"metadata":{"id":"aRYLXzJC8Zem"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save weights after every epoch\n","DataGen = ImageDataGenerator(rotation_range=20,width_shift_range=0.15,height_shift_range=0.15,zoom_range=0.2,horizontal_flip=True)\n","def Generator(x_train,gender_train,y_train,batch_size):\n","    loopcount = len(y_train)//batch_size\n","    i=0\n","    while (True):\n","        if i>loopcount:\n","            i=0\n","        # i=np.random.randint(0,loopcount)\n","        x_train_batch = x_train[i*batch_size:(i+1)*batch_size,:,:,:]\n","        x_train_batch = DataAugment(x_train_batch)\n","        gender_train_batch = gender_train[i*batch_size:(i+1)*batch_size]\n","        y_train_batch = y_train[i*batch_size:(i+1)*batch_size]\n","        inputs = [x_train_batch,gender_train_batch]\n","        target = y_train_batch\n","        yield (inputs ,target)\n","        i = i+1"],"metadata":{"id":"JQF8GIfw7o_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.asarray(dataHand, dtype=np.float32)\n","print (data.shape)\n","\n","dataR1 = np.asarray(dataR1, dtype=np.float32)\n","dataE = np.asarray(dataE, dtype=np.float32)\n","#data[:,:,:,0] = dataR1[:,:,:,0]\n","data[:,:,:,1] = dataR1[:,:,:,1]\n","data[:,:,:,2] = dataE[:,:,:,2]\n","print (dataR1.shape)\n","\n","age = np.asarray(age)\n","gender = np.asarray(gender)\n","print (age.shape)"],"metadata":{"id":"2NTZ3mXP-gld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","data /= 255.\n","gender =2*( gender-0.5)\n","x_final = []\n","y_final = []\n","gender_final = []\n","\n","# Shuffle images and split into train, validation and test sets\n","#random_no = np.random.choice(data.shape[0], size=data.shape[0], replace=False)\n","random_no = np.arange(dataR1.shape[0])\n","np.random.seed(0)\n","np.random.shuffle(random_no)\n","for i in random_no:\n","    x_final.append(data[i,:,:,:])\n","    y_final.append(age[i])\n","    gender_final.append(gender[i])\n","\n","x_final = np.asarray(x_final)\n","y_final = np.asarray(y_final)\n","gender_final = np.asarray(gender_final)\n","#print (y_final[:50])\n","#print (gender_final[:50])\n","k = 55 # Decides split count\n","x_test = x_final[:k,:,:,:]\n","y_test = y_final[:k]\n","gender_test = gender_final[:k]\n","x_valid = x_final[k:2*k,:,:,:]\n","y_valid = y_final[k:2*k]\n","gender_valid = gender_final[k:2*k]\n","x_train = x_final[2*k:,:,:,:]\n","y_train = y_final[2*k:]\n","gender_train = gender_final[2*k:]\n"],"metadata":{"id":"gh2Ne_KW-AwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del data\n","del dataR1\n","del dataE\n","del x_final\n","\n","## \n","#y_test = keras.utils.to_categorical(y_test,240)\n","#y_train = keras.utils.to_categorical(y_train,240)\n","#y_valid = keras.utils.to_categorical(y_valid,240)\n","#y_train = softlabel(y_train,240)\n","#y_valid = softlabel(y_valid,240)\n","#y_test = softlabel(y_test,240)\n","\n","\n","print ('x_train shape:'+ str(x_train.shape))\n","print ('y_train shape:'+ str(y_train.shape))\n","print ('gender_train shape:'+ str(gender_train.shape))\n","print ('x_valid shape:'+ str(x_valid.shape))\n","print ('y_valid shape:'+ str(y_valid.shape))\n","print ('gender_valid shape:' + str(gender_valid.shape))\n","print ('x_test shape:'+ str(x_test.shape))\n","print ('y_test shape:'+ str(y_test.shape))"],"metadata":{"id":"2CdA1G9aFo-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = keras.callbacks.ModelCheckpoint(filepath=os.path.join(mydrive,'weights2/weights.{epoch:02d}-{val_loss:.2f}.hdf5'),save_weights_only=True)\n","history = model.fit_generator(DataGen.flow([x_train,gender_train],y_train,batch_size=batch_size),steps_per_epoch=np.ceil(len(y_train)/batch_size),epochs=40,verbose=1,validation_data=([x_valid,gender_valid],y_valid))\n","#history = model.fit_generator(Generator(x_train,gender_train,y_train,batch_size),steps_per_epoch=np.ceil(len(y_train)/batch_size),epochs=10,verbose=1,validation_data=([x_valid,gender_valid],y_valid))\n","#history = model.fit([x_train,gender_train],y_train,batch_size=batch_size,epochs=80,verbose=1,validation_data=([x_valid,gender_valid],y_valid), callbacks = [checkpoint])\n","score = model.evaluate([x_test,gender_test], y_test, batch_size=batch_size)\n","print('Test loss:', score[0])\n","print('Test MAE:', score[1])\n","\n","##Visulization\n","weights=model.layers[-1].get_weights()[0]\n","print (weights.shape)"],"metadata":{"id":"1xnQ-NCW7mA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#past weights\n","os.listdir('/content/drive/MyDrive/weight2/')"],"metadata":{"id":"jAZ0J5oA7X81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TestMAE = TestMAE(model,x_test,y_test,gender_test)\n","print ('TestMAE:',TestMAE)"],"metadata":{"id":"Jg1gMkF4rP3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#part2\n","#for layer in base_model.layers[:16]:\n","#    layer.trainable=False\n","#for layer in base_model.layers:\n","#    print (layer.name,layer.trainable)\n","Adam=tensorflow.keras.optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999)\n","model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n","#history = model.fit_generator(Generator(x_train,gender_train,y_train,batch_size),steps_per_epoch=np.ceil(len(y_train)/batch_size),epochs=30,verbose=1,validation_data=([x_valid,gender_valid],y_valid))\n","history = model.fit([x_train,gender_train], y_train,batch_size=batch_size,epochs=20,verbose=1,validation_data=([x_valid,gender_valid],y_valid), callbacks = [checkpoint])\n","score = model.evaluate([x_test,gender_test], y_test, batch_size=batch_size)\n","print('Test loss:', score[0])\n","print('Test MAE:', score[1])"],"metadata":{"id":"Srp1zoEZ7iNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_weights(os.path.join(mydrive,\"modelagg.h5\")\n","with open('historyagg.pkl', 'wb') as f:\n","\tpickle.dump(history.history, f)\n","f.close()"],"metadata":{"id":"YWV2HgLQ62c2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"RSNA-BAA.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}